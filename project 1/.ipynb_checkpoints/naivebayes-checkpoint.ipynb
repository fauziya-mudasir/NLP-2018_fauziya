{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import *\n",
    "import re\n",
    "import random\n",
    "import sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_naive_bayes(textdoc):\n",
    "    testClasses={}\n",
    "    global pcount\n",
    "    global ncount\n",
    "    classes={}\n",
    "    dataset=[]\n",
    "    trainSet=[]\n",
    "    testSet=[]\n",
    "    vocablen=0    \n",
    "    probneg=0\n",
    "    probpos=0\n",
    "    neglen=0\n",
    "    poslen=0\n",
    "    accuracy=0\n",
    "    likelihood_sump=0\n",
    "    likelihood_sumn=0\n",
    "    def read_reviews():\n",
    "       \n",
    "        ##SPLITTING DATA INTO TRAIN AND TEST\n",
    "        filepath=(\"yelp_labelled.txt\",\"amazon_cells_labelled.txt\",\"imdb_labelled.txt\")\n",
    "        for file in filepath:\n",
    "            with open(file, 'r') as doc:\n",
    "                for line in doc:\n",
    "                    dataset.append(line)\n",
    "                random.shuffle(dataset)\n",
    "                trainSet=dataset[0:int(len(dataset)*0.8)]\n",
    "                testSet= dataset[int(len(dataset)*0.8):]\n",
    "        return(trainSet,testSet)\n",
    "\n",
    "    train_set, test_set=read_reviews()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-ba29ef2a6c66>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdocs_final\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mposcount\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnegcount\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtotal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mdocsFinal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mposcount\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnegcount\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtotal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0mposbag\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_set' is not defined"
     ]
    }
   ],
   "source": [
    "    def train(data):\n",
    "        docs=[]\n",
    "        poscount=0\n",
    "        negcount=0\n",
    "        total=0\n",
    "        for lines in data:\n",
    "            cleanline=re.sub(r\"['\\n\\t!():;&$?*#^@+]\",\"\",lines.lower())\n",
    "            cleandoc=re.sub(r\"[/,._-]\",\" \",cleanline.lower())\n",
    "           \n",
    "\n",
    "            docs.extend(cleandoc.split()[0:-1])\n",
    "            docs_final=list(set(docs))\n",
    "\n",
    "            key =int(cleandoc[-1])\n",
    "            if key == 1:\n",
    "                poscount+=1\n",
    "            else:\n",
    "                negcount+=1\n",
    "            if classes.get(key)!= None:\n",
    "                classes[key].extend(cleandoc.split()[0:-1])\n",
    "            else:\n",
    "                classes[key] = [cleandoc.split()[0:-1]]\n",
    "            total+=1\n",
    "            cleandocs=re.sub(r\"[0-9]+\",\"\",cleandoc)\n",
    "        return (docs_final,poscount,negcount,total)\n",
    "    \n",
    "    docsFinal,poscount,negcount,total=train(train_set)\n",
    "    \n",
    "    posbag=classes[1]\n",
    "    negbag=classes[0]        \n",
    "    vocablen=len(docsFinal)\n",
    "    probneg=np.log((negcount)/(total))\n",
    "    probpos=np.log((poscount)/(total))\n",
    "    poslen=len(posbag)\n",
    "    neglen=len(negbag)\n",
    "    wordLikelihood={}\n",
    "    def likeLihood(tdocs):\n",
    "        for i in tdocs:\n",
    "            likelihoodp=np.log(posbag.count(i)+1)/(poslen + vocablen)\n",
    "            likelihoodn=np.log(negbag.count(i)+1)/(neglen + vocablen)\n",
    "            wordLikelihood[i]=(likelihoodp,likelihoodn)\n",
    "        return (wordLikelihood)\n",
    "    \n",
    "    word_likelihood=likeLihood(docsFinal)\n",
    "\n",
    "\n",
    "    print(\"words in  vocab : {}\".format(len(docsFinal)))\n",
    "    print(\"words in  posbag : {}\".format(poslen))\n",
    "    print(\"words in  negbag : {}\".format(neglen))\n",
    "    #print(\"Bag of vocab : {}\".format(docs))\n",
    "    print(\"Log_prior neg  : {}\".format((negcount)/(total)))\n",
    "    print(\"Log_prior pos : {}\".format((poscount)/(total)))\n",
    "    #print(\"Bag of  negwords : {}\".format(negbag))\n",
    "    #print(\"Bag of poswords :{}\".format(posbag))\n",
    "    #print(\"likelihood for positiveclass :{}\".format(poslikelihood))\n",
    "    #print(\"likelihood for negativeclass :{}\".format(neglikelihood))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data):\n",
    "    docs=[]\n",
    "    poscount=0\n",
    "    negcount=0\n",
    "     total=0\n",
    "    for lines in data:\n",
    "         cleanline=re.sub(r\"['\\n\\t!():;&$?*#^@+]\",\"\",lines.lower())\n",
    "        cleandoc=re.sub(r\"[/,._-]\",\" \",cleanline.lower())\n",
    "           \n",
    "\n",
    "        docs.extend(cleandoc.split()[0:-1])\n",
    "        docs_final=list(set(docs))\n",
    "\n",
    "        key =int(cleandoc[-1])\n",
    "        if key == 1:\n",
    "               poscount+=1\n",
    "        else:\n",
    "               negcount+=1\n",
    "        if classes.get(key)!= None:\n",
    "               classes[key].extend(cleandoc.split()[0:-1])\n",
    "        else:\n",
    "               classes[key] = [cleandoc.split()[0:-1]]\n",
    "        total+=1\n",
    "        cleandocs=re.sub(r\"[0-9]+\",\"\",cleandoc)\n",
    "        return (docs_final,poscount,negcount,total)\n",
    "    \n",
    "    docsFinal,poscount,negcount,total=train(train_set)\n",
    "    \n",
    "    posbag=classes[1]\n",
    "    negbag=classes[0]        \n",
    "    vocablen=len(docsFinal)\n",
    "    probneg=np.log((negcount)/(total))\n",
    "    probpos=np.log((poscount)/(total))\n",
    "    poslen=len(posbag)\n",
    "    neglen=len(negbag)\n",
    "    wordLikelihood={}\n",
    "    def likeLihood(tdocs):\n",
    "        for i in tdocs:\n",
    "            likelihoodp=np.log(posbag.count(i)+1)/(poslen + vocablen)\n",
    "            likelihoodn=np.log(negbag.count(i)+1)/(neglen + vocablen)\n",
    "            wordLikelihood[i]=(likelihoodp,likelihoodn)\n",
    "        return (wordLikelihood)\n",
    "    \n",
    "    word_likelihood=likeLihood(docsFinal)\n",
    "\n",
    "\n",
    "    print(\"words in  vocab : {}\".format(len(docsFinal)))\n",
    "    print(\"words in  posbag : {}\".format(poslen))\n",
    "    print(\"words in  negbag : {}\".format(neglen))\n",
    "    #print(\"Bag of vocab : {}\".format(docs))\n",
    "    print(\"Log_prior neg  : {}\".format((negcount)/(total)))\n",
    "    print(\"Log_prior pos : {}\".format((poscount)/(total)))\n",
    "    #print(\"Bag of  negwords : {}\".format(negbag))\n",
    "    #print(\"Bag of poswords :{}\".format(posbag))\n",
    "    #print(\"likelihood for positiveclass :{}\".format(poslikelihood))\n",
    "    #print(\"likelihood for negativeclass :{}\".format(neglikelihood))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   def test(tdoc):\n",
    "        for line in tdoc:\n",
    "            text=re.sub(r\"['\\n\\t!():;&$?*#^@+]\",\"\",line.lower())\n",
    "            cleantext=re.sub(r\"[/,._-]\",\" \",text.lower())\n",
    "            \n",
    "            \n",
    "            key =int(cleantext[-1])\n",
    "            if testClasses.get(key)!= None:\n",
    "                testClasses[key].extend(cleantext.split()[0:-1])\n",
    "            else:\n",
    "                testClasses[key] = [cleantext.split()[0:-1]]\n",
    "        cleantexts=re.sub(r\"[0-9]+\",\"\",cleantext)\n",
    "        return(testClasses)\n",
    "    testClasses=test(test_set)\n",
    "    def tests(classtest,likelihood):\n",
    "        corrects=0\n",
    "        total=0    \n",
    "        for line in testClasses[1]:\n",
    "            pcount=1\n",
    "            ncount=1\n",
    "            total+=1\n",
    "            for words in line:\n",
    "                if words in wordLikelihood.keys():\n",
    "                    pcount +=wordLikelihood[words][1]*probpos\n",
    "                    ncount +=wordLikelihood[words][0]*probneg\n",
    "                    p= pcount\n",
    "                    n= ncount\n",
    "            if p>n :\n",
    "                corrects+=1\n",
    "        for line in testClasses[0]:\n",
    "            pcount=1\n",
    "            ncount=1\n",
    "            total+=1\n",
    "            for words in line:\n",
    "                if words in wordLikelihood.keys():\n",
    "                    pcount *=wordLikelihood[words][1]*probpos\n",
    "                    ncount *=wordLikelihood[words][0] * probneg\n",
    "                    p=pcount\n",
    "                    n= ncount\n",
    "            if p < n :\n",
    "                corrects+=1\n",
    "        accuracy=((corrects/total)*100)\n",
    "        print(\"the accuracy of the clasifier is: \",accuracy)\n",
    "    tests(testClasses,wordLikelihood)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    def testpos(tdoc):\n",
    "        with open(tdoc, 'r') as doc:\n",
    "            for line in doc:\n",
    "                text=re.sub(r\"['\\n\\t!():;&$?*#^@+]\",\"\",line.lower())\n",
    "                cleantexts=re.sub(r\"[/,._-]\",\" \",text.lower())\n",
    "                cleantext=re.sub(r\"[0-9]+\",\"\",cleantexts)\n",
    "                texts=(cleantext.split())\n",
    "                poslike={}\n",
    "                for i in texts:\n",
    "                    likepos=np.log((posbag.count(i)+1)/(poslen + vocablen))\n",
    "                    poslike[i]={likepos}\n",
    "                    pvalues =poslike.values()\n",
    "                    sum1 =0\n",
    "                    for i in pvalues:\n",
    "                        for r in i:\n",
    "                            sum1 += r\n",
    "        likelihood_sump =sum1 *probpos\n",
    "        print(\"The probability that the statement is positive is : {}\".format(likelihood_sump))\n",
    "        return (likelihood_sump)\n",
    "    p=testpos(textdoc)\n",
    "     \n",
    "    def testneg(tdoc):\n",
    "         with open(tdoc, 'r') as doc:\n",
    "            for line in doc:\n",
    "                 text=re.sub(r\"['\\n\\t!():;&$?*#^@+]\",\"\", line.lower())\n",
    "                cleantexts=re.sub(r\"[/,._-]\",\" \",text.lower())\n",
    "                cleantext=re.sub(r\"[0-9]+\",\"\",cleantexts)\n",
    "                texts=(cleantext.split())\n",
    "                 \n",
    "                neglike={}\n",
    "                 for i in texts:\n",
    "                    likeneg=np.log((negbag.count(i)+1)/(neglen + vocablen))\n",
    "                    neglike[i]={likeneg}\n",
    "                    nvalues =neglike.values()\n",
    "                    sum2 =0 \n",
    "                    for i in nvalues:\n",
    "                        for r in i:\n",
    "                             sum2 += r\n",
    "        likelihood_sumn =sum2 *probneg\n",
    "        print(\"The probability that the statement is negative is : {}\".format(likelihood_sumn))                \n",
    "             \n",
    "        return (likelihood_sumn)\n",
    "    n=testneg(textdoc)\n",
    "     \n",
    "    results =open(\"result.txt\",\"w+\")\n",
    "    if p > n:\n",
    "        results .write('The statement has a  positive sentiment 1')\n",
    "        print('The statement has a positive sentiment 1')\n",
    "    else:\n",
    "        results .write('The statement has a  negative sentiment 0')\n",
    "        print('The statement is negative 0')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(): \n",
    "    script = sys.argv[0]\n",
    "    file_name = sys.arg[1]\n",
    "    my_naive_bayes(file_name)\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
